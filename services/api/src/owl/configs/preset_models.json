[
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/gpt-5.2",
    "name": "OpenAI GPT-5.2",
    "type": "llm",
    "context_length": 400000,
    "max_output_tokens": 128000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 1.75,
    "llm_output_cost_per_mtoken": 14.0,
    "deployments": [
      {
        "name": "OpenAI GPT-5.2 Deployment",
        "provider": "openai",
        "routing_id": "openai/gpt-5.2",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/gpt-5.1",
    "name": "OpenAI GPT-5.1",
    "type": "llm",
    "context_length": 400000,
    "max_output_tokens": 128000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 1.25,
    "llm_output_cost_per_mtoken": 10.0,
    "deployments": [
      {
        "name": "OpenAI GPT-5.1 Deployment",
        "provider": "openai",
        "routing_id": "openai/gpt-5.1",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/gpt-5",
    "name": "OpenAI GPT-5",
    "type": "llm",
    "context_length": 400000,
    "max_output_tokens": 128000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 1.25,
    "llm_output_cost_per_mtoken": 10.0,
    "deployments": [
      {
        "name": "OpenAI GPT-5 Deployment",
        "provider": "openai",
        "routing_id": "openai/gpt-5",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/gpt-5-mini",
    "name": "OpenAI GPT-5 Mini",
    "type": "llm",
    "context_length": 400000,
    "max_output_tokens": 128000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.25,
    "llm_output_cost_per_mtoken": 2.0,
    "deployments": [
      {
        "name": "OpenAI GPT-5 Mini Deployment",
        "provider": "openai",
        "routing_id": "openai/gpt-5-mini",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/gpt-5-nano",
    "name": "OpenAI GPT-5 Nano",
    "type": "llm",
    "context_length": 400000,
    "max_output_tokens": 128000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.05,
    "llm_output_cost_per_mtoken": 0.4,
    "deployments": [
      {
        "name": "OpenAI GPT-5 Nano Deployment",
        "provider": "openai",
        "routing_id": "openai/gpt-5-nano",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "anthropic"
    },
    "id": "anthropic/claude-opus-4-5",
    "name": "Anthropic Claude Opus 4.5",
    "type": "llm",
    "context_length": 200000,
    "max_output_tokens": 64000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 5.0,
    "llm_output_cost_per_mtoken": 25.0,
    "deployments": [
      {
        "name": "Anthropic Claude Opus 4.5 Deployment",
        "provider": "anthropic",
        "routing_id": "anthropic/claude-opus-4-5",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "anthropic"
    },
    "id": "anthropic/claude-sonnet-4-5",
    "name": "Anthropic Claude Sonnet 4.5",
    "type": "llm",
    "context_length": 200000,
    "max_output_tokens": 64000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 3.0,
    "llm_output_cost_per_mtoken": 15.0,
    "deployments": [
      {
        "name": "Anthropic Claude Sonnet 4.5 Deployment",
        "provider": "anthropic",
        "routing_id": "anthropic/claude-sonnet-4-5",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "anthropic"
    },
    "id": "anthropic/claude-haiku-4-5",
    "name": "Anthropic Claude Haiku 4.5",
    "type": "llm",
    "context_length": 200000,
    "max_output_tokens": 64000,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 1.0,
    "llm_output_cost_per_mtoken": 5.0,
    "deployments": [
      {
        "name": "Anthropic Claude Haiku 4.5 Deployment",
        "provider": "anthropic",
        "routing_id": "anthropic/claude-haiku-4-5",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "google"
    },
    "id": "google/gemini-3-pro-preview",
    "name": "Google Gemini 3 Pro Preview",
    "type": "llm",
    "context_length": 1048576,
    "max_output_tokens": 65536,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 4.0,
    "llm_output_cost_per_mtoken": 18.0,
    "deployments": [
      {
        "name": "Google Gemini 3 Pro Preview Deployment",
        "provider": "gemini",
        "routing_id": "gemini/gemini-3-pro-preview",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "google"
    },
    "id": "google/gemini-2.5-pro",
    "name": "Google Gemini 2.5 Pro",
    "type": "llm",
    "context_length": 1048576,
    "max_output_tokens": 65536,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 2.5,
    "llm_output_cost_per_mtoken": 15.0,
    "deployments": [
      {
        "name": "Google Gemini 2.5 Pro Deployment",
        "provider": "gemini",
        "routing_id": "gemini/gemini-2.5-pro",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "google"
    },
    "id": "google/gemini-3-flash-preview",
    "name": "Google Gemini 3 Flash Preview",
    "type": "llm",
    "context_length": 1048576,
    "max_output_tokens": 65536,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.5,
    "llm_output_cost_per_mtoken": 3.0,
    "deployments": [
      {
        "name": "Google Gemini 3 Flash Preview Deployment",
        "provider": "gemini",
        "routing_id": "gemini/gemini-3-flash-preview",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "google"
    },
    "id": "google/gemini-2.5-flash-preview-09-2025",
    "name": "Google Gemini 2.5 Flash Preview",
    "type": "llm",
    "context_length": 1048576,
    "max_output_tokens": 65536,
    "capabilities": ["chat", "image", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.3,
    "llm_output_cost_per_mtoken": 2.5,
    "deployments": [
      {
        "name": "Google Gemini 2.5 Flash Preview Deployment",
        "provider": "gemini",
        "routing_id": "gemini/gemini-2.5-flash-preview-09-2025",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "meta"
    },
    "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "name": "Meta Llama 4 Scout (109B-A17B)",
    "type": "llm",
    "context_length": 262144,
    "capabilities": ["chat", "image"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.15,
    "llm_output_cost_per_mtoken": 0.5,
    "deployments": [
      {
        "name": "Meta Llama 4 Scout (109B-A17B) Deployment",
        "huggingface_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "cpu_count": "4",
        "memory_gb": "24",
        "required_vram": "140",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "meta"
    },
    "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "name": "Meta Llama 4 Maverick (400B-A17B)",
    "type": "llm",
    "context_length": 262144,
    "capabilities": ["chat", "image"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.35,
    "llm_output_cost_per_mtoken": 0.95,
    "deployments": [
      {
        "name": "Meta Llama 4 Maverick (400B-A17B) Deployment",
        "huggingface_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "cpu_count": "4",
        "memory_gb": "24",
        "required_vram": "320",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "deepseek"
    },
    "id": "deepseek-ai/DeepSeek-V3.2",
    "name": "DeepSeek V3.2 (685B-A22B)",
    "type": "llm",
    "context_length": 131072,
    "capabilities": ["chat", "reasoning", "tool"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.9,
    "llm_output_cost_per_mtoken": 1.2,
    "deployments": [
      {
        "name": "DeepSeek V3.2 (685B-A22B) Deployment",
        "huggingface_id": "deepseek-ai/DeepSeek-V3.2",
        "cpu_count": "4",
        "memory_gb": "8",
        "required_vram": "1100",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "deepseek"
    },
    "id": "deepseek-ai/DeepSeek-V3-0324",
    "name": "DeepSeek V3 (685B-A22B)",
    "type": "llm",
    "context_length": 131072,
    "capabilities": ["chat"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.9,
    "llm_output_cost_per_mtoken": 1.2,
    "deployments": [
      {
        "name": "DeepSeek V3 (685B-A22B) Deployment",
        "huggingface_id": "deepseek-ai/DeepSeek-V3-0324",
        "cpu_count": "4",
        "memory_gb": "8",
        "required_vram": "1100",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "deepseek"
    },
    "id": "deepseek-ai/DeepSeek-R1",
    "name": "DeepSeek R1 (685B-A22B)",
    "type": "llm",
    "context_length": 131072,
    "capabilities": ["chat"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 1.6,
    "llm_output_cost_per_mtoken": 2.5,
    "deployments": [
      {
        "name": "DeepSeek R1 (685B-A22B) Deployment",
        "huggingface_id": "deepseek-ai/DeepSeek-R1",
        "cpu_count": "4",
        "memory_gb": "8",
        "required_vram": "1100",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "qwen"
    },
    "id": "Qwen/Qwen3-235B-A22B-Thinking",
    "name": "Qwen 3 Thinking (235B-A22B)",
    "type": "llm",
    "context_length": 256000,
    "capabilities": ["chat", "reasoning"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.7,
    "llm_output_cost_per_mtoken": 0.7,
    "deployments": [
      {
        "name": "Qwen 3 Thinking (235B-A22B) Deployment",
        "huggingface_id": "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
        "cpu_count": "8",
        "memory_gb": "16",
        "required_vram": "280",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "qwen"
    },
    "id": "Qwen/Qwen3-235B-A22B-Instruct",
    "name": "Qwen 3 (235B-A22B)",
    "type": "llm",
    "context_length": 256000,
    "capabilities": ["chat"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.7,
    "llm_output_cost_per_mtoken": 0.7,
    "deployments": [
      {
        "name": "Qwen 3 (235B-A22B) Deployment",
        "huggingface_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
        "cpu_count": "8",
        "memory_gb": "16",
        "required_vram": "280",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "qwen"
    },
    "id": "Qwen/Qwen3-30B-A3B-Instruct",
    "name": "Qwen 3 (30B-A3B)",
    "type": "llm",
    "context_length": 256000,
    "capabilities": ["chat"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.25,
    "llm_output_cost_per_mtoken": 0.25,
    "deployments": [
      {
        "name": "Qwen 3 (30B-A3B) Deployment",
        "huggingface_id": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
        "cpu_count": "4",
        "memory_gb": "8",
        "required_vram": "42",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "qwen"
    },
    "id": "Qwen/Qwen3-VL-235B-A22B-Thinking",
    "name": "Qwen 3 VL Thinking (235B-A22B)",
    "type": "llm",
    "context_length": 256000,
    "capabilities": ["chat", "image", "reasoning"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.75,
    "llm_output_cost_per_mtoken": 0.75,
    "deployments": [
      {
        "name": "Qwen 3 VL Thinking (235B-A22B) Deployment",
        "huggingface_id": "Qwen/Qwen3-VL-235B-A22B-Thinking-FP8",
        "cpu_count": "8",
        "memory_gb": "32",
        "required_vram": "280",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "qwen"
    },
    "id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
    "name": "Qwen 3 VL (235B-A22B)",
    "type": "llm",
    "context_length": 256000,
    "capabilities": ["chat", "image"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.75,
    "llm_output_cost_per_mtoken": 0.75,
    "deployments": [
      {
        "name": "Qwen 3 VL (235B-A22B) Deployment",
        "huggingface_id": "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
        "cpu_count": "8",
        "memory_gb": "32",
        "required_vram": "280",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "qwen"
    },
    "id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
    "name": "Qwen 3 VL (30B-A3B)",
    "type": "llm",
    "context_length": 256000,
    "capabilities": ["chat", "image"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 0.3,
    "llm_output_cost_per_mtoken": 0.3,
    "deployments": [
      {
        "name": "Qwen 3 VL (30B-A3B) Deployment",
        "huggingface_id": "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8",
        "cpu_count": "4",
        "memory_gb": "16",
        "required_vram": "42",
        "num_replicas": 1,
        "provider": "vllm"
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/text-embedding-3-large-3072",
    "name": "OpenAI Text Embedding 3 Large (3072-dim)",
    "type": "embed",
    "context_length": 8192,
    "capabilities": ["embed"],
    "languages": ["en", "mul"],
    "embedding_size": 3072,
    "embedding_cost_per_mtoken": 0.13,
    "deployments": [
      {
        "name": "OpenAI Text Embedding 3 Large (3072-dim) Deployment",
        "provider": "openai",
        "routing_id": "openai/text-embedding-3-large",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/text-embedding-3-large-256",
    "name": "OpenAI Text Embedding 3 Large (256-dim)",
    "type": "embed",
    "context_length": 8192,
    "capabilities": ["embed"],
    "languages": ["en", "mul"],
    "embedding_size": 3072,
    "embedding_dimensions": 256,
    "embedding_cost_per_mtoken": 0.13,
    "deployments": [
      {
        "name": "OpenAI Text Embedding 3 Large (256-dim) Deployment",
        "provider": "openai",
        "routing_id": "openai/text-embedding-3-large",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/text-embedding-3-small-1536",
    "name": "OpenAI Text Embedding 3 Small (1536-dim)",
    "type": "embed",
    "context_length": 8192,
    "capabilities": ["embed"],
    "languages": ["en", "mul"],
    "embedding_size": 1536,
    "embedding_cost_per_mtoken": 0.02,
    "deployments": [
      {
        "name": "OpenAI Text Embedding 3 Small (1536-dim) Deployment",
        "provider": "openai",
        "routing_id": "openai/text-embedding-3-small",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/text-embedding-3-small-256",
    "name": "OpenAI Text Embedding 3 Small (256-dim)",
    "type": "embed",
    "context_length": 8192,
    "capabilities": ["embed"],
    "languages": ["en", "mul"],
    "embedding_size": 1536,
    "embedding_dimensions": 256,
    "embedding_cost_per_mtoken": 0.02,
    "deployments": [
      {
        "name": "OpenAI Text Embedding 3 Small (256-dim) Deployment",
        "provider": "openai",
        "routing_id": "openai/text-embedding-3-small",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "cohere"
    },
    "id": "cohere/embed-v4.0-256",
    "name": "Cohere Embed v4.0 (256-dim)",
    "type": "embed",
    "context_length": 128000,
    "capabilities": ["embed"],
    "languages": ["en", "mul"],
    "embedding_size": 1536,
    "embedding_dimensions": 256,
    "embedding_cost_per_mtoken": 0.12,
    "deployments": [
      {
        "name": "Cohere Embed v4.0 (256-dim) Deployment",
        "provider": "cohere",
        "routing_id": "embed-v4.0",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "cohere"
    },
    "id": "cohere/embed-multilingual-v3.0",
    "name": "Cohere Embed Multilingual v3.0",
    "type": "embed",
    "context_length": 512,
    "capabilities": ["embed"],
    "languages": ["en", "mul"],
    "embedding_size": 1024,
    "embedding_cost_per_mtoken": 0.11,
    "deployments": [
      {
        "name": "Cohere Embed Multilingual v3.0 Deployment",
        "provider": "cohere",
        "routing_id": "embed-multilingual-v3.0",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "generic"
    },
    "id": "BAAI/bge-m3",
    "name": "BAAI BGE-M3",
    "type": "embed",
    "context_length": 8192,
    "capabilities": ["embed"],
    "languages": ["en", "mul"],
    "embedding_cost_per_mtoken": 0.022,
    "deployments": [
      {
        "name": "BAAI BGE-M3 Deployment",
        "huggingface_id": "BAAI/bge-m3",
        "cpu_count": "2",
        "memory_gb": "4",
        "required_vram": "14",
        "num_replicas": 1,
        "provider": "infinity"
      }
    ]
  },
  {
    "meta": {
      "icon": "cohere"
    },
    "id": "cohere/rerank-multilingual-v3.0",
    "name": "Cohere Rerank Multilingual v3.0",
    "type": "rerank",
    "context_length": 512,
    "capabilities": ["rerank"],
    "languages": ["en", "mul"],
    "reranking_cost_per_ksearch": 2,
    "deployments": [
      {
        "name": "Cohere Rerank Multilingual v3.0 Deployment",
        "provider": "cohere",
        "routing_id": "rerank-multilingual-v3.0",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "generic"
    },
    "id": "BAAI/bge-reranker-v2-m3",
    "name": "BGE Reranker V2 M3",
    "type": "rerank",
    "context_length": 8192,
    "capabilities": ["rerank"],
    "languages": ["en", "mul"],
    "reranking_cost_per_ksearch": 2,
    "deployments": [
      {
        "name": "BGE Reranker V2 M3 Deployment",
        "huggingface_id": "BAAI/bge-reranker-v2-m3",
        "cpu_count": "2",
        "memory_gb": "4",
        "required_vram": "14",
        "num_replicas": 1,
        "provider": "infinity"
      }
    ]
  },
  {
    "meta": {
      "icon": "openai"
    },
    "id": "openai/gpt-image-1.5",
    "name": "OpenAI GPT Image",
    "type": "image_gen",
    "context_length": 200000,
    "capabilities": ["image_out", "image"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 5.0,
    "llm_output_cost_per_mtoken": 10.0,
    "image_input_cost_per_mtoken": 8.0,
    "image_output_cost_per_mtoken": 32.0,
    "deployments": [
      {
        "name": "OpenAI GPT Image Deployment",
        "provider": "openai",
        "routing_id": "openai/gpt-image-1.5",
        "api_base": ""
      }
    ]
  },
  {
    "meta": {
      "icon": "gemini"
    },
    "id": "gemini/gemini-3-pro-image-preview",
    "name": "Gemini 3 Pro Image Preview",
    "type": "image_gen",
    "context_length": 1048576,
    "capabilities": ["image_out", "image"],
    "languages": ["en", "mul"],
    "llm_input_cost_per_mtoken": 2.0,
    "llm_output_cost_per_mtoken": 12.0,
    "image_input_cost_per_mtoken": 2.0,
    "image_output_cost_per_mtoken": 120.0,
    "deployments": [
      {
        "name": "Gemini 3 Pro Image Preview Deployment",
        "provider": "gemini",
        "routing_id": "gemini/gemini-3-pro-image-preview",
        "api_base": ""
      }
    ]
  }
]
